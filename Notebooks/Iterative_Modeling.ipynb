{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>br_2</th>\n",
       "      <th>...</th>\n",
       "      <th>gd_4</th>\n",
       "      <th>gd_5</th>\n",
       "      <th>gd_6</th>\n",
       "      <th>gd_7</th>\n",
       "      <th>gd_8</th>\n",
       "      <th>gd_9</th>\n",
       "      <th>gd_10</th>\n",
       "      <th>gd_11</th>\n",
       "      <th>gd_12</th>\n",
       "      <th>wf_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>-1.096635</td>\n",
       "      <td>-0.304539</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>-0.992008</td>\n",
       "      <td>-0.319209</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0.870195</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>-0.245102</td>\n",
       "      <td>0.137043</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-2.175269</td>\n",
       "      <td>0.502317</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1.286644</td>\n",
       "      <td>0.218571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0.185533</td>\n",
       "      <td>-0.477261</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>-0.944324</td>\n",
       "      <td>-0.504090</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>-0.203973</td>\n",
       "      <td>0.201026</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>0.109869</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sqft_living  sqft_lot  sqft_above  sqft_basement  yr_built  \\\n",
       "0  221900.0    -1.096635 -0.304539        1180            0.0      1955   \n",
       "1  538000.0     0.870195  0.046284        2170          400.0      1951   \n",
       "2  180000.0    -2.175269  0.502317         770            0.0      1933   \n",
       "3  604000.0     0.185533 -0.477261        1050          910.0      1965   \n",
       "4  510000.0    -0.203973  0.201026        1680            0.0      1987   \n",
       "\n",
       "   yr_renovated  sqft_living15  sqft_lot15  br_2  ...  gd_4  gd_5  gd_6  gd_7  \\\n",
       "0        1955.0      -0.992008   -0.319209     0  ...     0     0     0     1   \n",
       "1        1991.0      -0.245102    0.137043     0  ...     0     0     0     1   \n",
       "2        1933.0       1.286644    0.218571     1  ...     0     0     1     0   \n",
       "3        1965.0      -0.944324   -0.504090     0  ...     0     0     0     1   \n",
       "4        1987.0      -0.042143    0.109869     0  ...     0     0     0     0   \n",
       "\n",
       "   gd_8  gd_9  gd_10  gd_11  gd_12  wf_1.0  \n",
       "0     0     0      0      0      0       0  \n",
       "1     0     0      0      0      0       0  \n",
       "2     0     0      0      0      0       0  \n",
       "3     0     0      0      0      0       0  \n",
       "4     1     0      0      0      0       0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('model_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error: 18734722588.94\n",
      "Test Mean Squared Error: 18450854084.6\n",
      "R Squared: 0.612\n",
      "Mean Absolute Error: 104553.88\n",
      "Root Mean Squared Error: 135833.92\n",
      "Average Predicted Price: 480476.9\n",
      "Average Actual Price: 480593.35\n",
      "Difference: -116.45\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "# our feature variables\n",
    "X = df.drop(['price'], axis=1)\n",
    "\n",
    "# our target variable\n",
    "y = df['price']\n",
    "\n",
    "# separate our data into testing and training subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=2)\n",
    "\n",
    "# fitting our training feature variables to our training target variable (price)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# predicted prices from our training subset\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "\n",
    "# predicted prices from our testing subset\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "# calculating residuals\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "# calculate mean square error for our test and training results\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', round(train_mse,2))\n",
    "print('Test Mean Squared Error:', round(test_mse,2))\n",
    "\n",
    "# calculate r-squared\n",
    "r2 = round(linreg.score(X,y), 3)\n",
    "print(\"R Squared:\", r2)\n",
    "\n",
    "# calculate mean absolute error\n",
    "mean_abs_err = metrics.mean_absolute_error(y_test, y_hat_test)\n",
    "print(\"Mean Absolute Error:\", round(mean_abs_err,2))\n",
    "\n",
    "# calculate root mean squared error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_hat_test))\n",
    "print(\"Root Mean Squared Error:\", round(rmse,2))\n",
    "\n",
    "# calculate mean predicted price and mean actual price\n",
    "average_predicted_price = y_hat_test.mean()\n",
    "average_actual_price = y_test.mean()\n",
    "print(\"Average Predicted Price:\", round(average_predicted_price,2))\n",
    "print(\"Average Actual Price:\", round(average_actual_price,2))\n",
    "print(\"Difference:\", round(average_predicted_price - average_actual_price, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R-Squared of .61, but RSME is 135,833.92 meaning that my model is about $135,833 off of the price value of a home.\n",
    "# This will be my baseline as I start to look further into how to tighten this model up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price'], axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.613</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   613.7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Nov 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:43:41</td>     <th>  Log-Likelihood:    </th> <td>-2.6278e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19842</td>      <th>  AIC:               </th>  <td>5.257e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19790</td>      <th>  BIC:               </th>  <td>5.261e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    51</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td> 5.237e+06</td> <td> 1.89e+05</td> <td>   27.775</td> <td> 0.000</td> <td> 4.87e+06</td> <td> 5.61e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>   <td> 3533.3721</td> <td> 5168.306</td> <td>    0.684</td> <td> 0.494</td> <td>-6596.941</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>      <td>-1.785e+04</td> <td> 2478.162</td> <td>   -7.202</td> <td> 0.000</td> <td>-2.27e+04</td> <td> -1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>    <td>   78.8323</td> <td>    6.608</td> <td>   11.931</td> <td> 0.000</td> <td>   65.881</td> <td>   91.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th> <td>   90.3593</td> <td>    6.825</td> <td>   13.239</td> <td> 0.000</td> <td>   76.981</td> <td>  103.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>      <td>-3011.6636</td> <td>   94.819</td> <td>  -31.762</td> <td> 0.000</td> <td>-3197.516</td> <td>-2825.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th>  <td>  316.4296</td> <td>   96.700</td> <td>    3.272</td> <td> 0.001</td> <td>  126.890</td> <td>  505.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th> <td> 4.418e+04</td> <td> 1614.682</td> <td>   27.364</td> <td> 0.000</td> <td>  4.1e+04</td> <td> 4.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot15</th>    <td>-1.634e+04</td> <td> 2376.987</td> <td>   -6.874</td> <td> 0.000</td> <td> -2.1e+04</td> <td>-1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_2</th>          <td> 1.818e+04</td> <td>  1.1e+04</td> <td>    1.650</td> <td> 0.099</td> <td>-3410.511</td> <td> 3.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_3</th>          <td>-5623.1347</td> <td> 1.12e+04</td> <td>   -0.502</td> <td> 0.616</td> <td>-2.76e+04</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_4</th>          <td>-1.852e+04</td> <td> 1.15e+04</td> <td>   -1.612</td> <td> 0.107</td> <td> -4.1e+04</td> <td> 3995.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_5</th>          <td>-2.713e+04</td> <td> 1.21e+04</td> <td>   -2.245</td> <td> 0.025</td> <td>-5.08e+04</td> <td>-3445.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_6</th>          <td>-3.251e+04</td> <td>  1.5e+04</td> <td>   -2.173</td> <td> 0.030</td> <td>-6.18e+04</td> <td>-3181.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_7</th>          <td>-4.363e+04</td> <td> 2.83e+04</td> <td>   -1.541</td> <td> 0.123</td> <td>-9.91e+04</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_8</th>          <td>-3.515e+04</td> <td> 4.99e+04</td> <td>   -0.704</td> <td> 0.482</td> <td>-1.33e+05</td> <td> 6.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_0.75</th>     <td> 1.239e+05</td> <td> 7.07e+04</td> <td>    1.751</td> <td> 0.080</td> <td>-1.48e+04</td> <td> 2.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.0</th>      <td> 1.105e+05</td> <td> 6.85e+04</td> <td>    1.613</td> <td> 0.107</td> <td>-2.38e+04</td> <td> 2.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.25</th>     <td> 1.159e+05</td> <td> 8.58e+04</td> <td>    1.350</td> <td> 0.177</td> <td>-5.23e+04</td> <td> 2.84e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.5</th>      <td> 1.132e+05</td> <td> 6.86e+04</td> <td>    1.651</td> <td> 0.099</td> <td>-2.12e+04</td> <td> 2.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.75</th>     <td> 1.254e+05</td> <td> 6.86e+04</td> <td>    1.829</td> <td> 0.067</td> <td>-8983.593</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.0</th>      <td>  1.26e+05</td> <td> 6.86e+04</td> <td>    1.837</td> <td> 0.066</td> <td>-8476.562</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.25</th>     <td>  1.35e+05</td> <td> 6.86e+04</td> <td>    1.968</td> <td> 0.049</td> <td>  526.953</td> <td>  2.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.5</th>      <td> 1.251e+05</td> <td> 6.86e+04</td> <td>    1.823</td> <td> 0.068</td> <td>-9428.790</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.75</th>     <td> 1.526e+05</td> <td> 6.87e+04</td> <td>    2.220</td> <td> 0.026</td> <td> 1.79e+04</td> <td> 2.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.0</th>      <td> 1.527e+05</td> <td> 6.88e+04</td> <td>    2.219</td> <td> 0.026</td> <td> 1.78e+04</td> <td> 2.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.25</th>     <td>  1.77e+05</td> <td>  6.9e+04</td> <td>    2.566</td> <td> 0.010</td> <td> 4.18e+04</td> <td> 3.12e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.5</th>      <td> 1.891e+05</td> <td> 6.89e+04</td> <td>    2.744</td> <td> 0.006</td> <td>  5.4e+04</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.75</th>     <td> 2.329e+05</td> <td> 7.02e+04</td> <td>    3.318</td> <td> 0.001</td> <td> 9.53e+04</td> <td>  3.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.0</th>      <td> 1.891e+05</td> <td> 7.05e+04</td> <td>    2.680</td> <td> 0.007</td> <td> 5.08e+04</td> <td> 3.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.25</th>     <td> 2.058e+05</td> <td> 7.33e+04</td> <td>    2.806</td> <td> 0.005</td> <td>  6.2e+04</td> <td> 3.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.5</th>      <td> 1.422e+05</td> <td> 7.16e+04</td> <td>    1.987</td> <td> 0.047</td> <td> 1917.636</td> <td> 2.83e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.75</th>     <td> 1.612e+05</td> <td> 9.23e+04</td> <td>    1.747</td> <td> 0.081</td> <td>-1.96e+04</td> <td> 3.42e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_1.5</th>       <td> 9761.6661</td> <td> 4021.947</td> <td>    2.427</td> <td> 0.015</td> <td> 1878.313</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.0</th>       <td> 7076.1217</td> <td> 3618.912</td> <td>    1.955</td> <td> 0.051</td> <td>  -17.249</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.5</th>       <td> 3.618e+04</td> <td> 1.38e+04</td> <td>    2.630</td> <td> 0.009</td> <td> 9215.146</td> <td> 6.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.0</th>       <td> 7.264e+04</td> <td> 7341.541</td> <td>    9.895</td> <td> 0.000</td> <td> 5.83e+04</td> <td>  8.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.5</th>       <td>  7.11e+04</td> <td> 5.61e+04</td> <td>    1.267</td> <td> 0.205</td> <td>-3.89e+04</td> <td> 1.81e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_2</th>         <td> 3.472e+04</td> <td> 2.97e+04</td> <td>    1.168</td> <td> 0.243</td> <td>-2.35e+04</td> <td>  9.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_3</th>         <td> 6.819e+04</td> <td> 2.76e+04</td> <td>    2.467</td> <td> 0.014</td> <td>  1.4e+04</td> <td> 1.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_4</th>         <td> 8.704e+04</td> <td> 2.76e+04</td> <td>    3.148</td> <td> 0.002</td> <td> 3.28e+04</td> <td> 1.41e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_5</th>         <td> 1.191e+05</td> <td> 2.78e+04</td> <td>    4.281</td> <td> 0.000</td> <td> 6.45e+04</td> <td> 1.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_4</th>          <td> 4608.8762</td> <td>  1.4e+05</td> <td>    0.033</td> <td> 0.974</td> <td> -2.7e+05</td> <td> 2.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_5</th>          <td>  292.3987</td> <td> 1.38e+05</td> <td>    0.002</td> <td> 0.998</td> <td>-2.71e+05</td> <td> 2.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_6</th>          <td> 5.291e+04</td> <td> 1.38e+05</td> <td>    0.383</td> <td> 0.702</td> <td>-2.18e+05</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_7</th>          <td> 1.355e+05</td> <td> 1.38e+05</td> <td>    0.980</td> <td> 0.327</td> <td>-1.36e+05</td> <td> 4.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_8</th>          <td>  2.29e+05</td> <td> 1.38e+05</td> <td>    1.655</td> <td> 0.098</td> <td>-4.22e+04</td> <td>    5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_9</th>          <td>  3.59e+05</td> <td> 1.38e+05</td> <td>    2.594</td> <td> 0.009</td> <td> 8.78e+04</td> <td>  6.3e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_10</th>         <td> 4.451e+05</td> <td> 1.38e+05</td> <td>    3.214</td> <td> 0.001</td> <td> 1.74e+05</td> <td> 7.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_11</th>         <td> 5.389e+05</td> <td> 1.39e+05</td> <td>    3.881</td> <td> 0.000</td> <td> 2.67e+05</td> <td> 8.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_12</th>         <td> 5.429e+05</td> <td> 1.49e+05</td> <td>    3.634</td> <td> 0.000</td> <td>  2.5e+05</td> <td> 8.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wf_1.0</th>        <td> 2.617e+05</td> <td> 1.91e+04</td> <td>   13.729</td> <td> 0.000</td> <td> 2.24e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1224.675</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2132.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.478</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.290</td>  <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.612\n",
       "Method:                 Least Squares   F-statistic:                     613.7\n",
       "Date:                Mon, 09 Nov 2020   Prob (F-statistic):               0.00\n",
       "Time:                        20:43:41   Log-Likelihood:            -2.6278e+05\n",
       "No. Observations:               19842   AIC:                         5.257e+05\n",
       "Df Residuals:                   19790   BIC:                         5.261e+05\n",
       "Df Model:                          51                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const          5.237e+06   1.89e+05     27.775      0.000    4.87e+06    5.61e+06\n",
       "sqft_living    3533.3721   5168.306      0.684      0.494   -6596.941    1.37e+04\n",
       "sqft_lot      -1.785e+04   2478.162     -7.202      0.000   -2.27e+04    -1.3e+04\n",
       "sqft_above       78.8323      6.608     11.931      0.000      65.881      91.784\n",
       "sqft_basement    90.3593      6.825     13.239      0.000      76.981     103.737\n",
       "yr_built      -3011.6636     94.819    -31.762      0.000   -3197.516   -2825.811\n",
       "yr_renovated    316.4296     96.700      3.272      0.001     126.890     505.970\n",
       "sqft_living15  4.418e+04   1614.682     27.364      0.000     4.1e+04    4.73e+04\n",
       "sqft_lot15    -1.634e+04   2376.987     -6.874      0.000    -2.1e+04   -1.17e+04\n",
       "br_2           1.818e+04    1.1e+04      1.650      0.099   -3410.511    3.98e+04\n",
       "br_3          -5623.1347   1.12e+04     -0.502      0.616   -2.76e+04    1.64e+04\n",
       "br_4          -1.852e+04   1.15e+04     -1.612      0.107    -4.1e+04    3995.057\n",
       "br_5          -2.713e+04   1.21e+04     -2.245      0.025   -5.08e+04   -3445.675\n",
       "br_6          -3.251e+04    1.5e+04     -2.173      0.030   -6.18e+04   -3181.750\n",
       "br_7          -4.363e+04   2.83e+04     -1.541      0.123   -9.91e+04    1.18e+04\n",
       "br_8          -3.515e+04   4.99e+04     -0.704      0.482   -1.33e+05    6.27e+04\n",
       "bath_0.75      1.239e+05   7.07e+04      1.751      0.080   -1.48e+04    2.62e+05\n",
       "bath_1.0       1.105e+05   6.85e+04      1.613      0.107   -2.38e+04    2.45e+05\n",
       "bath_1.25      1.159e+05   8.58e+04      1.350      0.177   -5.23e+04    2.84e+05\n",
       "bath_1.5       1.132e+05   6.86e+04      1.651      0.099   -2.12e+04    2.48e+05\n",
       "bath_1.75      1.254e+05   6.86e+04      1.829      0.067   -8983.593     2.6e+05\n",
       "bath_2.0        1.26e+05   6.86e+04      1.837      0.066   -8476.562     2.6e+05\n",
       "bath_2.25       1.35e+05   6.86e+04      1.968      0.049     526.953     2.7e+05\n",
       "bath_2.5       1.251e+05   6.86e+04      1.823      0.068   -9428.790     2.6e+05\n",
       "bath_2.75      1.526e+05   6.87e+04      2.220      0.026    1.79e+04    2.87e+05\n",
       "bath_3.0       1.527e+05   6.88e+04      2.219      0.026    1.78e+04    2.88e+05\n",
       "bath_3.25       1.77e+05    6.9e+04      2.566      0.010    4.18e+04    3.12e+05\n",
       "bath_3.5       1.891e+05   6.89e+04      2.744      0.006     5.4e+04    3.24e+05\n",
       "bath_3.75      2.329e+05   7.02e+04      3.318      0.001    9.53e+04     3.7e+05\n",
       "bath_4.0       1.891e+05   7.05e+04      2.680      0.007    5.08e+04    3.27e+05\n",
       "bath_4.25      2.058e+05   7.33e+04      2.806      0.005     6.2e+04    3.49e+05\n",
       "bath_4.5       1.422e+05   7.16e+04      1.987      0.047    1917.636    2.83e+05\n",
       "bath_4.75      1.612e+05   9.23e+04      1.747      0.081   -1.96e+04    3.42e+05\n",
       "flr_1.5        9761.6661   4021.947      2.427      0.015    1878.313    1.76e+04\n",
       "flr_2.0        7076.1217   3618.912      1.955      0.051     -17.249    1.42e+04\n",
       "flr_2.5        3.618e+04   1.38e+04      2.630      0.009    9215.146    6.32e+04\n",
       "flr_3.0        7.264e+04   7341.541      9.895      0.000    5.83e+04     8.7e+04\n",
       "flr_3.5         7.11e+04   5.61e+04      1.267      0.205   -3.89e+04    1.81e+05\n",
       "con_2          3.472e+04   2.97e+04      1.168      0.243   -2.35e+04     9.3e+04\n",
       "con_3          6.819e+04   2.76e+04      2.467      0.014     1.4e+04    1.22e+05\n",
       "con_4          8.704e+04   2.76e+04      3.148      0.002    3.28e+04    1.41e+05\n",
       "con_5          1.191e+05   2.78e+04      4.281      0.000    6.45e+04    1.74e+05\n",
       "gd_4           4608.8762    1.4e+05      0.033      0.974    -2.7e+05    2.79e+05\n",
       "gd_5            292.3987   1.38e+05      0.002      0.998   -2.71e+05    2.72e+05\n",
       "gd_6           5.291e+04   1.38e+05      0.383      0.702   -2.18e+05    3.24e+05\n",
       "gd_7           1.355e+05   1.38e+05      0.980      0.327   -1.36e+05    4.07e+05\n",
       "gd_8            2.29e+05   1.38e+05      1.655      0.098   -4.22e+04       5e+05\n",
       "gd_9            3.59e+05   1.38e+05      2.594      0.009    8.78e+04     6.3e+05\n",
       "gd_10          4.451e+05   1.38e+05      3.214      0.001    1.74e+05    7.16e+05\n",
       "gd_11          5.389e+05   1.39e+05      3.881      0.000    2.67e+05    8.11e+05\n",
       "gd_12          5.429e+05   1.49e+05      3.634      0.000     2.5e+05    8.36e+05\n",
       "wf_1.0         2.617e+05   1.91e+04     13.729      0.000    2.24e+05    2.99e+05\n",
       "==============================================================================\n",
       "Omnibus:                     1224.675   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2132.068\n",
       "Skew:                           0.478   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.290   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_int = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.53337215e+03, -1.78465884e+04,  7.88323163e+01,  9.03592944e+01,\n",
       "       -3.01166358e+03,  3.16429559e+02,  4.41836493e+04, -1.63392464e+04,\n",
       "        1.81800307e+04, -5.62313474e+03, -1.85180246e+04, -2.71320099e+04,\n",
       "       -3.25066265e+04, -4.36287709e+04, -3.51461239e+04,  1.23850744e+05,\n",
       "        1.10492906e+05,  1.15895842e+05,  1.13249421e+05,  1.25437447e+05,\n",
       "        1.25993271e+05,  1.35041734e+05,  1.25052114e+05,  1.52565618e+05,\n",
       "        1.52695168e+05,  1.76962685e+05,  1.89064665e+05,  2.32902334e+05,\n",
       "        1.89060610e+05,  2.05768510e+05,  1.42223686e+05,  1.61214116e+05,\n",
       "        9.76166608e+03,  7.07612168e+03,  3.61847653e+04,  7.26421041e+04,\n",
       "        7.11002447e+04,  3.47246724e+04,  6.81922314e+04,  8.70389639e+04,\n",
       "        1.19050684e+05,  4.60887619e+03,  2.92398684e+02,  5.29056881e+04,\n",
       "        1.35542930e+05,  2.29004878e+05,  3.59034122e+05,  4.45073190e+05,\n",
       "        5.38923247e+05,  5.42870816e+05,  2.61725862e+05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5237398.976990887"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise Selection\n",
    "\n",
    "### By using stepwise selection, I can see which specific features I can remove, based on their high p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  gd_9                           with p-value 0.0\n",
      "Add  sqft_living                    with p-value 0.0\n",
      "Add  yr_built                       with p-value 0.0\n",
      "Add  gd_10                          with p-value 0.0\n",
      "Add  gd_8                           with p-value 3.68677e-308\n",
      "Add  gd_11                          with p-value 0.0\n",
      "Add  sqft_lot                       with p-value 2.49991e-208\n",
      "Add  sqft_living15                  with p-value 1.42514e-151\n",
      "Add  gd_7                           with p-value 8.32235e-80\n",
      "Add  wf_1.0                         with p-value 2.23315e-45\n",
      "Add  con_5                          with p-value 8.29344e-29\n",
      "Add  gd_12                          with p-value 4.69426e-26\n",
      "Add  flr_3.0                        with p-value 4.56901e-25\n",
      "Add  br_2                           with p-value 2.17476e-21\n",
      "Add  bath_3.5                       with p-value 7.00226e-21\n",
      "Add  bath_3.25                      with p-value 1.38497e-13\n",
      "Add  bath_3.75                      with p-value 1.46474e-14\n",
      "Add  con_4                          with p-value 1.91062e-12\n",
      "Add  sqft_lot15                     with p-value 1.56498e-11\n",
      "Add  bath_2.75                      with p-value 5.40254e-08\n",
      "Add  sqft_basement                  with p-value 3.57283e-07\n",
      "Add  sqft_above                     with p-value 3.13027e-33\n",
      "Add  gd_6                           with p-value 1.40299e-08\n",
      "Drop sqft_living                    with p-value 0.0669357\n",
      "Add  br_3                           with p-value 2.16674e-07\n",
      "Add  yr_renovated                   with p-value 7.34988e-06\n",
      "Add  bath_3.0                       with p-value 3.10798e-05\n",
      "Add  bath_1.0                       with p-value 7.81921e-05\n",
      "Add  con_3                          with p-value 0.000382365\n",
      "Add  bath_1.5                       with p-value 0.000544701\n",
      "Add  bath_4.0                       with p-value 0.000790854\n",
      "Add  bath_2.25                      with p-value 0.00394708\n",
      "Add  bath_4.25                      with p-value 0.00355187\n",
      "resulting features:\n",
      "['gd_9', 'yr_built', 'gd_10', 'gd_8', 'gd_11', 'sqft_lot', 'sqft_living15', 'gd_7', 'wf_1.0', 'con_5', 'gd_12', 'flr_3.0', 'br_2', 'bath_3.5', 'bath_3.25', 'bath_3.75', 'con_4', 'sqft_lot15', 'bath_2.75', 'sqft_basement', 'sqft_above', 'gd_6', 'br_3', 'yr_renovated', 'bath_3.0', 'bath_1.0', 'con_3', 'bath_1.5', 'bath_4.0', 'bath_2.25', 'bath_4.25']\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(X, y, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement',\n",
       "       'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15', 'br_2',\n",
       "       'br_3', 'br_4', 'br_5', 'br_6', 'br_7', 'br_8', 'bath_0.75', 'bath_1.0',\n",
       "       'bath_1.25', 'bath_1.5', 'bath_1.75', 'bath_2.0', 'bath_2.25',\n",
       "       'bath_2.5', 'bath_2.75', 'bath_3.0', 'bath_3.25', 'bath_3.5',\n",
       "       'bath_3.75', 'bath_4.0', 'bath_4.25', 'bath_4.5', 'bath_4.75',\n",
       "       'flr_1.5', 'flr_2.0', 'flr_2.5', 'flr_3.0', 'flr_3.5', 'con_2', 'con_3',\n",
       "       'con_4', 'con_5', 'gd_4', 'gd_5', 'gd_6', 'gd_7', 'gd_8', 'gd_9',\n",
       "       'gd_10', 'gd_11', 'gd_12', 'wf_1.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original # of Feature Variables:  51\n",
      "Selected # of Feature Variables:  50\n",
      "# of Feature Variables Removed:  1\n"
     ]
    }
   ],
   "source": [
    "original_features_count = len(X.columns)\n",
    "stepwise_features = ['sqft_lot', 'sqft_above', 'sqft_basement',\n",
    "       'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15', 'br_2',\n",
    "       'br_3', 'br_4', 'br_5', 'br_6', 'br_7', 'br_8', 'bath_0.75', 'bath_1.0',\n",
    "       'bath_1.25', 'bath_1.5', 'bath_1.75', 'bath_2.0', 'bath_2.25',\n",
    "       'bath_2.5', 'bath_2.75', 'bath_3.0', 'bath_3.25', 'bath_3.5',\n",
    "       'bath_3.75', 'bath_4.0', 'bath_4.25', 'bath_4.5', 'bath_4.75',\n",
    "       'flr_1.5', 'flr_2.0', 'flr_2.5', 'flr_3.0', 'flr_3.5', 'con_2', 'con_3',\n",
    "       'con_4', 'con_5', 'gd_4', 'gd_5', 'gd_6', 'gd_7', 'gd_8', 'gd_9',\n",
    "       'gd_10', 'gd_11', 'gd_12', 'wf_1.0']\n",
    "stepwise_features_count = len(stepwise_features)\n",
    "print(\"Original # of Feature Variables: \", original_features_count)\n",
    "print(\"Selected # of Feature Variables: \", stepwise_features_count)\n",
    "print(\"# of Feature Variables Removed: \", original_features_count - stepwise_features_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now after removing the sqft_living, since it had a high p-value, I will run the test/train again as well as OLS to see how my model looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting for new features\n",
    "X_new = X[stepwise_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error: 18734760468.99\n",
      "Test Mean Squared Error: 18451757113.48\n",
      "R Squared: 0.612\n",
      "Mean Absolute Error: 104551.05\n",
      "Root Mean Squared Error: 135837.24\n",
      "Average Predicted Price: 480481.55\n",
      "Average Actual Price: 480593.35\n",
      "Difference: -111.8\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "# our feature variables\n",
    "X_new = X[stepwise_features]\n",
    "\n",
    "# our target variable\n",
    "y = df['price']\n",
    "\n",
    "# separate our data into testing and training subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,y, test_size=0.2, random_state=2)\n",
    "\n",
    "# fitting our training feature variables to our training target variable (price)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# predicted prices from our training subset\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "\n",
    "# predicted prices from our testing subset\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "# calculating residuals\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "# calculate mean square error for our test and training results\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', round(train_mse,2))\n",
    "print('Test Mean Squared Error:', round(test_mse,2))\n",
    "\n",
    "# calculate r-squared\n",
    "r2 = round(linreg.score(X_new,y), 3)\n",
    "print(\"R Squared:\", r2)\n",
    "\n",
    "# calculate mean absolute error\n",
    "mean_abs_err = metrics.mean_absolute_error(y_test, y_hat_test)\n",
    "print(\"Mean Absolute Error:\", round(mean_abs_err,2))\n",
    "\n",
    "# calculate root mean squared error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_hat_test))\n",
    "print(\"Root Mean Squared Error:\", round(rmse,2))\n",
    "\n",
    "# calculate mean predicted price and mean actual price\n",
    "average_predicted_price = y_hat_test.mean()\n",
    "average_actual_price = y_test.mean()\n",
    "print(\"Average Predicted Price:\", round(average_predicted_price,2))\n",
    "print(\"Average Actual Price:\", round(average_actual_price,2))\n",
    "print(\"Difference:\", round(average_predicted_price - average_actual_price, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.613</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   626.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 04 Nov 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:03:05</td>     <th>  Log-Likelihood:    </th> <td>-2.6278e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19842</td>      <th>  AIC:               </th>  <td>5.257e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19791</td>      <th>  BIC:               </th>  <td>5.261e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    50</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>  5.23e+06</td> <td> 1.88e+05</td> <td>   27.783</td> <td> 0.000</td> <td> 4.86e+06</td> <td>  5.6e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>      <td>-1.777e+04</td> <td> 2475.858</td> <td>   -7.179</td> <td> 0.000</td> <td>-2.26e+04</td> <td>-1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>    <td>   82.8057</td> <td>    3.143</td> <td>   26.343</td> <td> 0.000</td> <td>   76.645</td> <td>   88.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th> <td>   94.4214</td> <td>    3.358</td> <td>   28.115</td> <td> 0.000</td> <td>   87.839</td> <td>  101.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>      <td>-3014.3523</td> <td>   94.736</td> <td>  -31.819</td> <td> 0.000</td> <td>-3200.042</td> <td>-2828.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th>  <td>  316.4301</td> <td>   96.699</td> <td>    3.272</td> <td> 0.001</td> <td>  126.893</td> <td>  505.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th> <td>  4.43e+04</td> <td> 1606.156</td> <td>   27.579</td> <td> 0.000</td> <td> 4.11e+04</td> <td> 4.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot15</th>    <td>-1.638e+04</td> <td> 2376.216</td> <td>   -6.893</td> <td> 0.000</td> <td> -2.1e+04</td> <td>-1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_2</th>          <td> 1.931e+04</td> <td> 1.09e+04</td> <td>    1.773</td> <td> 0.076</td> <td>-2037.134</td> <td> 4.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_3</th>          <td>-3885.4948</td> <td> 1.09e+04</td> <td>   -0.356</td> <td> 0.722</td> <td>-2.53e+04</td> <td> 1.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_4</th>          <td>-1.667e+04</td> <td> 1.12e+04</td> <td>   -1.493</td> <td> 0.135</td> <td>-3.85e+04</td> <td> 5210.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_5</th>          <td>-2.538e+04</td> <td> 1.18e+04</td> <td>   -2.149</td> <td> 0.032</td> <td>-4.85e+04</td> <td>-2233.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_6</th>          <td>-3.075e+04</td> <td> 1.47e+04</td> <td>   -2.086</td> <td> 0.037</td> <td>-5.96e+04</td> <td>-1862.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_7</th>          <td>-4.177e+04</td> <td> 2.82e+04</td> <td>   -1.483</td> <td> 0.138</td> <td> -9.7e+04</td> <td> 1.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_8</th>          <td>-3.386e+04</td> <td> 4.99e+04</td> <td>   -0.679</td> <td> 0.497</td> <td>-1.32e+05</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_0.75</th>     <td> 1.233e+05</td> <td> 7.07e+04</td> <td>    1.743</td> <td> 0.081</td> <td>-1.53e+04</td> <td> 2.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.0</th>      <td> 1.104e+05</td> <td> 6.85e+04</td> <td>    1.611</td> <td> 0.107</td> <td>-2.39e+04</td> <td> 2.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.25</th>     <td> 1.165e+05</td> <td> 8.58e+04</td> <td>    1.357</td> <td> 0.175</td> <td>-5.18e+04</td> <td> 2.85e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.5</th>      <td> 1.137e+05</td> <td> 6.86e+04</td> <td>    1.658</td> <td> 0.097</td> <td>-2.07e+04</td> <td> 2.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.75</th>     <td> 1.262e+05</td> <td> 6.86e+04</td> <td>    1.840</td> <td> 0.066</td> <td>-8218.281</td> <td> 2.61e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.0</th>      <td> 1.268e+05</td> <td> 6.86e+04</td> <td>    1.848</td> <td> 0.065</td> <td>-7691.431</td> <td> 2.61e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.25</th>     <td> 1.359e+05</td> <td> 6.86e+04</td> <td>    1.981</td> <td> 0.048</td> <td> 1404.985</td> <td>  2.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.5</th>      <td>  1.26e+05</td> <td> 6.86e+04</td> <td>    1.836</td> <td> 0.066</td> <td>-8495.024</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.75</th>     <td> 1.534e+05</td> <td> 6.87e+04</td> <td>    2.232</td> <td> 0.026</td> <td> 1.87e+04</td> <td> 2.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.0</th>      <td> 1.535e+05</td> <td> 6.88e+04</td> <td>    2.231</td> <td> 0.026</td> <td> 1.86e+04</td> <td> 2.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.25</th>     <td> 1.774e+05</td> <td> 6.89e+04</td> <td>    2.574</td> <td> 0.010</td> <td> 4.23e+04</td> <td> 3.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.5</th>      <td> 1.895e+05</td> <td> 6.89e+04</td> <td>    2.750</td> <td> 0.006</td> <td> 5.45e+04</td> <td> 3.25e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.75</th>     <td>  2.33e+05</td> <td> 7.02e+04</td> <td>    3.320</td> <td> 0.001</td> <td> 9.54e+04</td> <td> 3.71e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.0</th>      <td> 1.891e+05</td> <td> 7.05e+04</td> <td>    2.680</td> <td> 0.007</td> <td> 5.08e+04</td> <td> 3.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.25</th>     <td> 2.053e+05</td> <td> 7.33e+04</td> <td>    2.800</td> <td> 0.005</td> <td> 6.16e+04</td> <td> 3.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.5</th>      <td> 1.421e+05</td> <td> 7.16e+04</td> <td>    1.985</td> <td> 0.047</td> <td> 1766.520</td> <td> 2.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.75</th>     <td> 1.596e+05</td> <td> 9.22e+04</td> <td>    1.731</td> <td> 0.084</td> <td>-2.12e+04</td> <td>  3.4e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_1.5</th>       <td> 1.002e+04</td> <td> 4004.601</td> <td>    2.501</td> <td> 0.012</td> <td> 2167.009</td> <td> 1.79e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.0</th>       <td> 7127.1565</td> <td> 3618.093</td> <td>    1.970</td> <td> 0.049</td> <td>   35.390</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.5</th>       <td> 3.629e+04</td> <td> 1.38e+04</td> <td>    2.638</td> <td> 0.008</td> <td> 9320.567</td> <td> 6.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.0</th>       <td> 7.268e+04</td> <td> 7341.261</td> <td>    9.900</td> <td> 0.000</td> <td> 5.83e+04</td> <td> 8.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.5</th>       <td> 7.127e+04</td> <td> 5.61e+04</td> <td>    1.270</td> <td> 0.204</td> <td>-3.87e+04</td> <td> 1.81e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_2</th>         <td> 3.476e+04</td> <td> 2.97e+04</td> <td>    1.170</td> <td> 0.242</td> <td>-2.35e+04</td> <td>  9.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_3</th>         <td> 6.831e+04</td> <td> 2.76e+04</td> <td>    2.471</td> <td> 0.013</td> <td> 1.41e+04</td> <td> 1.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_4</th>         <td> 8.717e+04</td> <td> 2.76e+04</td> <td>    3.153</td> <td> 0.002</td> <td>  3.3e+04</td> <td> 1.41e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_5</th>         <td> 1.192e+05</td> <td> 2.78e+04</td> <td>    4.285</td> <td> 0.000</td> <td> 6.46e+04</td> <td> 1.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_4</th>          <td> 4999.9921</td> <td>  1.4e+05</td> <td>    0.036</td> <td> 0.971</td> <td>-2.69e+05</td> <td> 2.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_5</th>          <td> 1788.1123</td> <td> 1.38e+05</td> <td>    0.013</td> <td> 0.990</td> <td>-2.69e+05</td> <td> 2.73e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_6</th>          <td> 5.508e+04</td> <td> 1.38e+05</td> <td>    0.398</td> <td> 0.690</td> <td>-2.16e+05</td> <td> 3.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_7</th>          <td> 1.382e+05</td> <td> 1.38e+05</td> <td>    1.000</td> <td> 0.317</td> <td>-1.33e+05</td> <td> 4.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_8</th>          <td> 2.318e+05</td> <td> 1.38e+05</td> <td>    1.676</td> <td> 0.094</td> <td>-3.93e+04</td> <td> 5.03e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_9</th>          <td> 3.616e+05</td> <td> 1.38e+05</td> <td>    2.614</td> <td> 0.009</td> <td> 9.04e+04</td> <td> 6.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_10</th>         <td> 4.471e+05</td> <td> 1.38e+05</td> <td>    3.230</td> <td> 0.001</td> <td> 1.76e+05</td> <td> 7.18e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_11</th>         <td> 5.401e+05</td> <td> 1.39e+05</td> <td>    3.890</td> <td> 0.000</td> <td> 2.68e+05</td> <td> 8.12e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_12</th>         <td> 5.433e+05</td> <td> 1.49e+05</td> <td>    3.637</td> <td> 0.000</td> <td>  2.5e+05</td> <td> 8.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wf_1.0</th>        <td> 2.619e+05</td> <td> 1.91e+04</td> <td>   13.743</td> <td> 0.000</td> <td> 2.25e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1227.614</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2139.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.478</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.293</td>  <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.612\n",
       "Method:                 Least Squares   F-statistic:                     626.0\n",
       "Date:                Wed, 04 Nov 2020   Prob (F-statistic):               0.00\n",
       "Time:                        14:03:05   Log-Likelihood:            -2.6278e+05\n",
       "No. Observations:               19842   AIC:                         5.257e+05\n",
       "Df Residuals:                   19791   BIC:                         5.261e+05\n",
       "Df Model:                          50                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const           5.23e+06   1.88e+05     27.783      0.000    4.86e+06     5.6e+06\n",
       "sqft_lot      -1.777e+04   2475.858     -7.179      0.000   -2.26e+04   -1.29e+04\n",
       "sqft_above       82.8057      3.143     26.343      0.000      76.645      88.967\n",
       "sqft_basement    94.4214      3.358     28.115      0.000      87.839     101.004\n",
       "yr_built      -3014.3523     94.736    -31.819      0.000   -3200.042   -2828.662\n",
       "yr_renovated    316.4301     96.699      3.272      0.001     126.893     505.968\n",
       "sqft_living15   4.43e+04   1606.156     27.579      0.000    4.11e+04    4.74e+04\n",
       "sqft_lot15    -1.638e+04   2376.216     -6.893      0.000    -2.1e+04   -1.17e+04\n",
       "br_2           1.931e+04   1.09e+04      1.773      0.076   -2037.134    4.07e+04\n",
       "br_3          -3885.4948   1.09e+04     -0.356      0.722   -2.53e+04    1.75e+04\n",
       "br_4          -1.667e+04   1.12e+04     -1.493      0.135   -3.85e+04    5210.901\n",
       "br_5          -2.538e+04   1.18e+04     -2.149      0.032   -4.85e+04   -2233.973\n",
       "br_6          -3.075e+04   1.47e+04     -2.086      0.037   -5.96e+04   -1862.679\n",
       "br_7          -4.177e+04   2.82e+04     -1.483      0.138    -9.7e+04    1.34e+04\n",
       "br_8          -3.386e+04   4.99e+04     -0.679      0.497   -1.32e+05     6.4e+04\n",
       "bath_0.75      1.233e+05   7.07e+04      1.743      0.081   -1.53e+04    2.62e+05\n",
       "bath_1.0       1.104e+05   6.85e+04      1.611      0.107   -2.39e+04    2.45e+05\n",
       "bath_1.25      1.165e+05   8.58e+04      1.357      0.175   -5.18e+04    2.85e+05\n",
       "bath_1.5       1.137e+05   6.86e+04      1.658      0.097   -2.07e+04    2.48e+05\n",
       "bath_1.75      1.262e+05   6.86e+04      1.840      0.066   -8218.281    2.61e+05\n",
       "bath_2.0       1.268e+05   6.86e+04      1.848      0.065   -7691.431    2.61e+05\n",
       "bath_2.25      1.359e+05   6.86e+04      1.981      0.048    1404.985     2.7e+05\n",
       "bath_2.5        1.26e+05   6.86e+04      1.836      0.066   -8495.024     2.6e+05\n",
       "bath_2.75      1.534e+05   6.87e+04      2.232      0.026    1.87e+04    2.88e+05\n",
       "bath_3.0       1.535e+05   6.88e+04      2.231      0.026    1.86e+04    2.88e+05\n",
       "bath_3.25      1.774e+05   6.89e+04      2.574      0.010    4.23e+04    3.13e+05\n",
       "bath_3.5       1.895e+05   6.89e+04      2.750      0.006    5.45e+04    3.25e+05\n",
       "bath_3.75       2.33e+05   7.02e+04      3.320      0.001    9.54e+04    3.71e+05\n",
       "bath_4.0       1.891e+05   7.05e+04      2.680      0.007    5.08e+04    3.27e+05\n",
       "bath_4.25      2.053e+05   7.33e+04      2.800      0.005    6.16e+04    3.49e+05\n",
       "bath_4.5       1.421e+05   7.16e+04      1.985      0.047    1766.520    2.82e+05\n",
       "bath_4.75      1.596e+05   9.22e+04      1.731      0.084   -2.12e+04     3.4e+05\n",
       "flr_1.5        1.002e+04   4004.601      2.501      0.012    2167.009    1.79e+04\n",
       "flr_2.0        7127.1565   3618.093      1.970      0.049      35.390    1.42e+04\n",
       "flr_2.5        3.629e+04   1.38e+04      2.638      0.008    9320.567    6.33e+04\n",
       "flr_3.0        7.268e+04   7341.261      9.900      0.000    5.83e+04    8.71e+04\n",
       "flr_3.5        7.127e+04   5.61e+04      1.270      0.204   -3.87e+04    1.81e+05\n",
       "con_2          3.476e+04   2.97e+04      1.170      0.242   -2.35e+04     9.3e+04\n",
       "con_3          6.831e+04   2.76e+04      2.471      0.013    1.41e+04    1.22e+05\n",
       "con_4          8.717e+04   2.76e+04      3.153      0.002     3.3e+04    1.41e+05\n",
       "con_5          1.192e+05   2.78e+04      4.285      0.000    6.46e+04    1.74e+05\n",
       "gd_4           4999.9921    1.4e+05      0.036      0.971   -2.69e+05    2.79e+05\n",
       "gd_5           1788.1123   1.38e+05      0.013      0.990   -2.69e+05    2.73e+05\n",
       "gd_6           5.508e+04   1.38e+05      0.398      0.690   -2.16e+05    3.26e+05\n",
       "gd_7           1.382e+05   1.38e+05      1.000      0.317   -1.33e+05    4.09e+05\n",
       "gd_8           2.318e+05   1.38e+05      1.676      0.094   -3.93e+04    5.03e+05\n",
       "gd_9           3.616e+05   1.38e+05      2.614      0.009    9.04e+04    6.33e+05\n",
       "gd_10          4.471e+05   1.38e+05      3.230      0.001    1.76e+05    7.18e+05\n",
       "gd_11          5.401e+05   1.39e+05      3.890      0.000    2.68e+05    8.12e+05\n",
       "gd_12          5.433e+05   1.49e+05      3.637      0.000     2.5e+05    8.36e+05\n",
       "wf_1.0         2.619e+05   1.91e+04     13.743      0.000    2.25e+05    2.99e+05\n",
       "==============================================================================\n",
       "Omnibus:                     1227.614   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2139.832\n",
       "Skew:                           0.478   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.293   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "XX = sm.add_constant(X_new)\n",
    "model = sm.OLS(y, XX).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There was a slight change, but I am still seeing some high p-values. I will run the stepwise selection a few more times to see how I can adjust my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  gd_9                           with p-value 0.0\n",
      "Add  sqft_living                    with p-value 0.0\n",
      "Add  yr_built                       with p-value 0.0\n",
      "Add  gd_10                          with p-value 0.0\n",
      "Add  gd_8                           with p-value 3.68677e-308\n",
      "Add  gd_11                          with p-value 0.0\n",
      "Add  sqft_lot                       with p-value 2.49991e-208\n",
      "Add  sqft_living15                  with p-value 1.42514e-151\n",
      "Add  gd_7                           with p-value 8.32235e-80\n",
      "Add  wf_1.0                         with p-value 2.23315e-45\n",
      "Add  con_5                          with p-value 8.29344e-29\n",
      "Add  gd_12                          with p-value 4.69426e-26\n",
      "Add  flr_3.0                        with p-value 4.56901e-25\n",
      "Add  br_2                           with p-value 2.17476e-21\n",
      "Add  bath_3.5                       with p-value 7.00226e-21\n",
      "Add  bath_3.25                      with p-value 1.38497e-13\n",
      "Add  bath_3.75                      with p-value 1.46474e-14\n",
      "Add  con_4                          with p-value 1.91062e-12\n",
      "Add  sqft_lot15                     with p-value 1.56498e-11\n",
      "Add  bath_2.75                      with p-value 5.40254e-08\n",
      "Add  sqft_basement                  with p-value 3.57283e-07\n",
      "Add  sqft_above                     with p-value 3.13027e-33\n",
      "Add  gd_6                           with p-value 1.40299e-08\n",
      "Drop sqft_living                    with p-value 0.0669357\n",
      "Add  br_3                           with p-value 2.16674e-07\n",
      "Add  yr_renovated                   with p-value 7.34988e-06\n",
      "Add  bath_3.0                       with p-value 3.10798e-05\n",
      "Add  bath_1.0                       with p-value 7.81921e-05\n",
      "Add  con_3                          with p-value 0.000382365\n",
      "Add  bath_1.5                       with p-value 0.000544701\n",
      "Add  bath_4.0                       with p-value 0.000790854\n",
      "Add  bath_2.25                      with p-value 0.00394708\n",
      "Add  bath_4.25                      with p-value 0.00355187\n",
      "resulting features:\n",
      "['gd_9', 'yr_built', 'gd_10', 'gd_8', 'gd_11', 'sqft_lot', 'sqft_living15', 'gd_7', 'wf_1.0', 'con_5', 'gd_12', 'flr_3.0', 'br_2', 'bath_3.5', 'bath_3.25', 'bath_3.75', 'con_4', 'sqft_lot15', 'bath_2.75', 'sqft_basement', 'sqft_above', 'gd_6', 'br_3', 'yr_renovated', 'bath_3.0', 'bath_1.0', 'con_3', 'bath_1.5', 'bath_4.0', 'bath_2.25', 'bath_4.25']\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(X, y, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = model.resid\n",
    "fig = sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
