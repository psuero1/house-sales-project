{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>br_2</th>\n",
       "      <th>...</th>\n",
       "      <th>gd_4</th>\n",
       "      <th>gd_5</th>\n",
       "      <th>gd_6</th>\n",
       "      <th>gd_7</th>\n",
       "      <th>gd_8</th>\n",
       "      <th>gd_9</th>\n",
       "      <th>gd_10</th>\n",
       "      <th>gd_11</th>\n",
       "      <th>gd_12</th>\n",
       "      <th>wf_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>-1.096635</td>\n",
       "      <td>-0.304539</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>-0.992008</td>\n",
       "      <td>-0.319209</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0.870195</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>-0.245102</td>\n",
       "      <td>0.137043</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>-2.175269</td>\n",
       "      <td>0.502317</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1.286644</td>\n",
       "      <td>0.218571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0.185533</td>\n",
       "      <td>-0.477261</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>-0.944324</td>\n",
       "      <td>-0.504090</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>-0.203973</td>\n",
       "      <td>0.201026</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>0.109869</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sqft_living  sqft_lot  sqft_above  sqft_basement  yr_built  \\\n",
       "0  221900.0    -1.096635 -0.304539        1180            0.0      1955   \n",
       "1  538000.0     0.870195  0.046284        2170          400.0      1951   \n",
       "2  180000.0    -2.175269  0.502317         770            0.0      1933   \n",
       "3  604000.0     0.185533 -0.477261        1050          910.0      1965   \n",
       "4  510000.0    -0.203973  0.201026        1680            0.0      1987   \n",
       "\n",
       "   yr_renovated  sqft_living15  sqft_lot15  br_2  ...  gd_4  gd_5  gd_6  gd_7  \\\n",
       "0        1955.0      -0.992008   -0.319209     0  ...     0     0     0     1   \n",
       "1        1991.0      -0.245102    0.137043     0  ...     0     0     0     1   \n",
       "2        1933.0       1.286644    0.218571     1  ...     0     0     1     0   \n",
       "3        1965.0      -0.944324   -0.504090     0  ...     0     0     0     1   \n",
       "4        1987.0      -0.042143    0.109869     0  ...     0     0     0     0   \n",
       "\n",
       "   gd_8  gd_9  gd_10  gd_11  gd_12  wf_1.0  \n",
       "0     0     0      0      0      0       0  \n",
       "1     0     0      0      0      0       0  \n",
       "2     0     0      0      0      0       0  \n",
       "3     0     0      0      0      0       0  \n",
       "4     1     0      0      0      0       0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('model_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error: 18734722588.94\n",
      "Test Mean Squared Error: 18450854084.6\n",
      "R Squared: 0.612\n",
      "Mean Absolute Error: 104553.88\n",
      "Root Mean Squared Error: 135833.92\n",
      "Average Predicted Price: 480476.9\n",
      "Average Actual Price: 480593.35\n",
      "Difference: -116.45\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "# our feature variables\n",
    "X = df.drop(['price'], axis=1)\n",
    "\n",
    "# our target variable\n",
    "y = df['price']\n",
    "\n",
    "# separate our data into testing and training subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=2)\n",
    "\n",
    "# fitting our training feature variables to our training target variable (price)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# predicted prices from our training subset\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "\n",
    "# predicted prices from our testing subset\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "# calculating residuals\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "# calculate mean square error for our test and training results\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', round(train_mse,2))\n",
    "print('Test Mean Squared Error:', round(test_mse,2))\n",
    "\n",
    "# calculate r-squared\n",
    "r2 = round(linreg.score(X,y), 3)\n",
    "print(\"R Squared:\", r2)\n",
    "\n",
    "# calculate mean absolute error\n",
    "mean_abs_err = metrics.mean_absolute_error(y_test, y_hat_test)\n",
    "print(\"Mean Absolute Error:\", round(mean_abs_err,2))\n",
    "\n",
    "# calculate root mean squared error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_hat_test))\n",
    "print(\"Root Mean Squared Error:\", round(rmse,2))\n",
    "\n",
    "# calculate mean predicted price and mean actual price\n",
    "average_predicted_price = y_hat_test.mean()\n",
    "average_actual_price = y_test.mean()\n",
    "print(\"Average Predicted Price:\", round(average_predicted_price,2))\n",
    "print(\"Average Actual Price:\", round(average_actual_price,2))\n",
    "print(\"Difference:\", round(average_predicted_price - average_actual_price, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R-Squared of .61, but RSME is 135,833.92 meaning that my model is about $135,833 off of the price value of a home.\n",
    "# This will be my baseline as I start to look further into how to tighten this model up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price'], axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.613</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   613.7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 04 Nov 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:58:45</td>     <th>  Log-Likelihood:    </th> <td>-2.6278e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19842</td>      <th>  AIC:               </th>  <td>5.257e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19790</td>      <th>  BIC:               </th>  <td>5.261e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    51</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td> 5.237e+06</td> <td> 1.89e+05</td> <td>   27.775</td> <td> 0.000</td> <td> 4.87e+06</td> <td> 5.61e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th>   <td> 3533.3721</td> <td> 5168.306</td> <td>    0.684</td> <td> 0.494</td> <td>-6596.941</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>      <td>-1.785e+04</td> <td> 2478.162</td> <td>   -7.202</td> <td> 0.000</td> <td>-2.27e+04</td> <td> -1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>    <td>   78.8323</td> <td>    6.608</td> <td>   11.931</td> <td> 0.000</td> <td>   65.881</td> <td>   91.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th> <td>   90.3593</td> <td>    6.825</td> <td>   13.239</td> <td> 0.000</td> <td>   76.981</td> <td>  103.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>      <td>-3011.6636</td> <td>   94.819</td> <td>  -31.762</td> <td> 0.000</td> <td>-3197.516</td> <td>-2825.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th>  <td>  316.4296</td> <td>   96.700</td> <td>    3.272</td> <td> 0.001</td> <td>  126.890</td> <td>  505.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th> <td> 4.418e+04</td> <td> 1614.682</td> <td>   27.364</td> <td> 0.000</td> <td>  4.1e+04</td> <td> 4.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot15</th>    <td>-1.634e+04</td> <td> 2376.987</td> <td>   -6.874</td> <td> 0.000</td> <td> -2.1e+04</td> <td>-1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_2</th>          <td> 1.818e+04</td> <td>  1.1e+04</td> <td>    1.650</td> <td> 0.099</td> <td>-3410.511</td> <td> 3.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_3</th>          <td>-5623.1347</td> <td> 1.12e+04</td> <td>   -0.502</td> <td> 0.616</td> <td>-2.76e+04</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_4</th>          <td>-1.852e+04</td> <td> 1.15e+04</td> <td>   -1.612</td> <td> 0.107</td> <td> -4.1e+04</td> <td> 3995.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_5</th>          <td>-2.713e+04</td> <td> 1.21e+04</td> <td>   -2.245</td> <td> 0.025</td> <td>-5.08e+04</td> <td>-3445.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_6</th>          <td>-3.251e+04</td> <td>  1.5e+04</td> <td>   -2.173</td> <td> 0.030</td> <td>-6.18e+04</td> <td>-3181.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_7</th>          <td>-4.363e+04</td> <td> 2.83e+04</td> <td>   -1.541</td> <td> 0.123</td> <td>-9.91e+04</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_8</th>          <td>-3.515e+04</td> <td> 4.99e+04</td> <td>   -0.704</td> <td> 0.482</td> <td>-1.33e+05</td> <td> 6.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_0.75</th>     <td> 1.239e+05</td> <td> 7.07e+04</td> <td>    1.751</td> <td> 0.080</td> <td>-1.48e+04</td> <td> 2.62e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.0</th>      <td> 1.105e+05</td> <td> 6.85e+04</td> <td>    1.613</td> <td> 0.107</td> <td>-2.38e+04</td> <td> 2.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.25</th>     <td> 1.159e+05</td> <td> 8.58e+04</td> <td>    1.350</td> <td> 0.177</td> <td>-5.23e+04</td> <td> 2.84e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.5</th>      <td> 1.132e+05</td> <td> 6.86e+04</td> <td>    1.651</td> <td> 0.099</td> <td>-2.12e+04</td> <td> 2.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.75</th>     <td> 1.254e+05</td> <td> 6.86e+04</td> <td>    1.829</td> <td> 0.067</td> <td>-8983.593</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.0</th>      <td>  1.26e+05</td> <td> 6.86e+04</td> <td>    1.837</td> <td> 0.066</td> <td>-8476.562</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.25</th>     <td>  1.35e+05</td> <td> 6.86e+04</td> <td>    1.968</td> <td> 0.049</td> <td>  526.953</td> <td>  2.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.5</th>      <td> 1.251e+05</td> <td> 6.86e+04</td> <td>    1.823</td> <td> 0.068</td> <td>-9428.790</td> <td>  2.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.75</th>     <td> 1.526e+05</td> <td> 6.87e+04</td> <td>    2.220</td> <td> 0.026</td> <td> 1.79e+04</td> <td> 2.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.0</th>      <td> 1.527e+05</td> <td> 6.88e+04</td> <td>    2.219</td> <td> 0.026</td> <td> 1.78e+04</td> <td> 2.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.25</th>     <td>  1.77e+05</td> <td>  6.9e+04</td> <td>    2.566</td> <td> 0.010</td> <td> 4.18e+04</td> <td> 3.12e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.5</th>      <td> 1.891e+05</td> <td> 6.89e+04</td> <td>    2.744</td> <td> 0.006</td> <td>  5.4e+04</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.75</th>     <td> 2.329e+05</td> <td> 7.02e+04</td> <td>    3.318</td> <td> 0.001</td> <td> 9.53e+04</td> <td>  3.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.0</th>      <td> 1.891e+05</td> <td> 7.05e+04</td> <td>    2.680</td> <td> 0.007</td> <td> 5.08e+04</td> <td> 3.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.25</th>     <td> 2.058e+05</td> <td> 7.33e+04</td> <td>    2.806</td> <td> 0.005</td> <td>  6.2e+04</td> <td> 3.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.5</th>      <td> 1.422e+05</td> <td> 7.16e+04</td> <td>    1.987</td> <td> 0.047</td> <td> 1917.636</td> <td> 2.83e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.75</th>     <td> 1.612e+05</td> <td> 9.23e+04</td> <td>    1.747</td> <td> 0.081</td> <td>-1.96e+04</td> <td> 3.42e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_1.5</th>       <td> 9761.6661</td> <td> 4021.947</td> <td>    2.427</td> <td> 0.015</td> <td> 1878.313</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.0</th>       <td> 7076.1217</td> <td> 3618.912</td> <td>    1.955</td> <td> 0.051</td> <td>  -17.249</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_2.5</th>       <td> 3.618e+04</td> <td> 1.38e+04</td> <td>    2.630</td> <td> 0.009</td> <td> 9215.146</td> <td> 6.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.0</th>       <td> 7.264e+04</td> <td> 7341.541</td> <td>    9.895</td> <td> 0.000</td> <td> 5.83e+04</td> <td>  8.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.5</th>       <td>  7.11e+04</td> <td> 5.61e+04</td> <td>    1.267</td> <td> 0.205</td> <td>-3.89e+04</td> <td> 1.81e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_2</th>         <td> 3.472e+04</td> <td> 2.97e+04</td> <td>    1.168</td> <td> 0.243</td> <td>-2.35e+04</td> <td>  9.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_3</th>         <td> 6.819e+04</td> <td> 2.76e+04</td> <td>    2.467</td> <td> 0.014</td> <td>  1.4e+04</td> <td> 1.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_4</th>         <td> 8.704e+04</td> <td> 2.76e+04</td> <td>    3.148</td> <td> 0.002</td> <td> 3.28e+04</td> <td> 1.41e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_5</th>         <td> 1.191e+05</td> <td> 2.78e+04</td> <td>    4.281</td> <td> 0.000</td> <td> 6.45e+04</td> <td> 1.74e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_4</th>          <td> 4608.8762</td> <td>  1.4e+05</td> <td>    0.033</td> <td> 0.974</td> <td> -2.7e+05</td> <td> 2.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_5</th>          <td>  292.3987</td> <td> 1.38e+05</td> <td>    0.002</td> <td> 0.998</td> <td>-2.71e+05</td> <td> 2.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_6</th>          <td> 5.291e+04</td> <td> 1.38e+05</td> <td>    0.383</td> <td> 0.702</td> <td>-2.18e+05</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_7</th>          <td> 1.355e+05</td> <td> 1.38e+05</td> <td>    0.980</td> <td> 0.327</td> <td>-1.36e+05</td> <td> 4.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_8</th>          <td>  2.29e+05</td> <td> 1.38e+05</td> <td>    1.655</td> <td> 0.098</td> <td>-4.22e+04</td> <td>    5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_9</th>          <td>  3.59e+05</td> <td> 1.38e+05</td> <td>    2.594</td> <td> 0.009</td> <td> 8.78e+04</td> <td>  6.3e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_10</th>         <td> 4.451e+05</td> <td> 1.38e+05</td> <td>    3.214</td> <td> 0.001</td> <td> 1.74e+05</td> <td> 7.16e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_11</th>         <td> 5.389e+05</td> <td> 1.39e+05</td> <td>    3.881</td> <td> 0.000</td> <td> 2.67e+05</td> <td> 8.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_12</th>         <td> 5.429e+05</td> <td> 1.49e+05</td> <td>    3.634</td> <td> 0.000</td> <td>  2.5e+05</td> <td> 8.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wf_1.0</th>        <td> 2.617e+05</td> <td> 1.91e+04</td> <td>   13.729</td> <td> 0.000</td> <td> 2.24e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1224.675</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2132.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.478</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.290</td>  <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.612\n",
       "Method:                 Least Squares   F-statistic:                     613.7\n",
       "Date:                Wed, 04 Nov 2020   Prob (F-statistic):               0.00\n",
       "Time:                        12:58:45   Log-Likelihood:            -2.6278e+05\n",
       "No. Observations:               19842   AIC:                         5.257e+05\n",
       "Df Residuals:                   19790   BIC:                         5.261e+05\n",
       "Df Model:                          51                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const          5.237e+06   1.89e+05     27.775      0.000    4.87e+06    5.61e+06\n",
       "sqft_living    3533.3721   5168.306      0.684      0.494   -6596.941    1.37e+04\n",
       "sqft_lot      -1.785e+04   2478.162     -7.202      0.000   -2.27e+04    -1.3e+04\n",
       "sqft_above       78.8323      6.608     11.931      0.000      65.881      91.784\n",
       "sqft_basement    90.3593      6.825     13.239      0.000      76.981     103.737\n",
       "yr_built      -3011.6636     94.819    -31.762      0.000   -3197.516   -2825.811\n",
       "yr_renovated    316.4296     96.700      3.272      0.001     126.890     505.970\n",
       "sqft_living15  4.418e+04   1614.682     27.364      0.000     4.1e+04    4.73e+04\n",
       "sqft_lot15    -1.634e+04   2376.987     -6.874      0.000    -2.1e+04   -1.17e+04\n",
       "br_2           1.818e+04    1.1e+04      1.650      0.099   -3410.511    3.98e+04\n",
       "br_3          -5623.1347   1.12e+04     -0.502      0.616   -2.76e+04    1.64e+04\n",
       "br_4          -1.852e+04   1.15e+04     -1.612      0.107    -4.1e+04    3995.057\n",
       "br_5          -2.713e+04   1.21e+04     -2.245      0.025   -5.08e+04   -3445.675\n",
       "br_6          -3.251e+04    1.5e+04     -2.173      0.030   -6.18e+04   -3181.750\n",
       "br_7          -4.363e+04   2.83e+04     -1.541      0.123   -9.91e+04    1.18e+04\n",
       "br_8          -3.515e+04   4.99e+04     -0.704      0.482   -1.33e+05    6.27e+04\n",
       "bath_0.75      1.239e+05   7.07e+04      1.751      0.080   -1.48e+04    2.62e+05\n",
       "bath_1.0       1.105e+05   6.85e+04      1.613      0.107   -2.38e+04    2.45e+05\n",
       "bath_1.25      1.159e+05   8.58e+04      1.350      0.177   -5.23e+04    2.84e+05\n",
       "bath_1.5       1.132e+05   6.86e+04      1.651      0.099   -2.12e+04    2.48e+05\n",
       "bath_1.75      1.254e+05   6.86e+04      1.829      0.067   -8983.593     2.6e+05\n",
       "bath_2.0        1.26e+05   6.86e+04      1.837      0.066   -8476.562     2.6e+05\n",
       "bath_2.25       1.35e+05   6.86e+04      1.968      0.049     526.953     2.7e+05\n",
       "bath_2.5       1.251e+05   6.86e+04      1.823      0.068   -9428.790     2.6e+05\n",
       "bath_2.75      1.526e+05   6.87e+04      2.220      0.026    1.79e+04    2.87e+05\n",
       "bath_3.0       1.527e+05   6.88e+04      2.219      0.026    1.78e+04    2.88e+05\n",
       "bath_3.25       1.77e+05    6.9e+04      2.566      0.010    4.18e+04    3.12e+05\n",
       "bath_3.5       1.891e+05   6.89e+04      2.744      0.006     5.4e+04    3.24e+05\n",
       "bath_3.75      2.329e+05   7.02e+04      3.318      0.001    9.53e+04     3.7e+05\n",
       "bath_4.0       1.891e+05   7.05e+04      2.680      0.007    5.08e+04    3.27e+05\n",
       "bath_4.25      2.058e+05   7.33e+04      2.806      0.005     6.2e+04    3.49e+05\n",
       "bath_4.5       1.422e+05   7.16e+04      1.987      0.047    1917.636    2.83e+05\n",
       "bath_4.75      1.612e+05   9.23e+04      1.747      0.081   -1.96e+04    3.42e+05\n",
       "flr_1.5        9761.6661   4021.947      2.427      0.015    1878.313    1.76e+04\n",
       "flr_2.0        7076.1217   3618.912      1.955      0.051     -17.249    1.42e+04\n",
       "flr_2.5        3.618e+04   1.38e+04      2.630      0.009    9215.146    6.32e+04\n",
       "flr_3.0        7.264e+04   7341.541      9.895      0.000    5.83e+04     8.7e+04\n",
       "flr_3.5         7.11e+04   5.61e+04      1.267      0.205   -3.89e+04    1.81e+05\n",
       "con_2          3.472e+04   2.97e+04      1.168      0.243   -2.35e+04     9.3e+04\n",
       "con_3          6.819e+04   2.76e+04      2.467      0.014     1.4e+04    1.22e+05\n",
       "con_4          8.704e+04   2.76e+04      3.148      0.002    3.28e+04    1.41e+05\n",
       "con_5          1.191e+05   2.78e+04      4.281      0.000    6.45e+04    1.74e+05\n",
       "gd_4           4608.8762    1.4e+05      0.033      0.974    -2.7e+05    2.79e+05\n",
       "gd_5            292.3987   1.38e+05      0.002      0.998   -2.71e+05    2.72e+05\n",
       "gd_6           5.291e+04   1.38e+05      0.383      0.702   -2.18e+05    3.24e+05\n",
       "gd_7           1.355e+05   1.38e+05      0.980      0.327   -1.36e+05    4.07e+05\n",
       "gd_8            2.29e+05   1.38e+05      1.655      0.098   -4.22e+04       5e+05\n",
       "gd_9            3.59e+05   1.38e+05      2.594      0.009    8.78e+04     6.3e+05\n",
       "gd_10          4.451e+05   1.38e+05      3.214      0.001    1.74e+05    7.16e+05\n",
       "gd_11          5.389e+05   1.39e+05      3.881      0.000    2.67e+05    8.11e+05\n",
       "gd_12          5.429e+05   1.49e+05      3.634      0.000     2.5e+05    8.36e+05\n",
       "wf_1.0         2.617e+05   1.91e+04     13.729      0.000    2.24e+05    2.99e+05\n",
       "==============================================================================\n",
       "Omnibus:                     1224.675   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2132.068\n",
       "Skew:                           0.478   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.290   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_int = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.53337215e+03, -1.78465884e+04,  7.88323163e+01,  9.03592944e+01,\n",
       "       -3.01166358e+03,  3.16429559e+02,  4.41836493e+04, -1.63392464e+04,\n",
       "        1.81800307e+04, -5.62313474e+03, -1.85180246e+04, -2.71320099e+04,\n",
       "       -3.25066265e+04, -4.36287709e+04, -3.51461239e+04,  1.23850744e+05,\n",
       "        1.10492906e+05,  1.15895842e+05,  1.13249421e+05,  1.25437447e+05,\n",
       "        1.25993271e+05,  1.35041734e+05,  1.25052114e+05,  1.52565618e+05,\n",
       "        1.52695168e+05,  1.76962685e+05,  1.89064665e+05,  2.32902334e+05,\n",
       "        1.89060610e+05,  2.05768510e+05,  1.42223686e+05,  1.61214116e+05,\n",
       "        9.76166608e+03,  7.07612168e+03,  3.61847653e+04,  7.26421041e+04,\n",
       "        7.11002447e+04,  3.47246724e+04,  6.81922314e+04,  8.70389639e+04,\n",
       "        1.19050684e+05,  4.60887619e+03,  2.92398684e+02,  5.29056881e+04,\n",
       "        1.35542930e+05,  2.29004878e+05,  3.59034122e+05,  4.45073190e+05,\n",
       "        5.38923247e+05,  5.42870816e+05,  2.61725862e+05])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5237398.976990887"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" \n",
    "    Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  gd_6                           with p-value 0.0\n",
      "Add  sqft_living                    with p-value 0.0\n",
      "Add  gd_7                           with p-value 2.01694e-294\n",
      "Add  yr_renovated                   with p-value 0.0\n",
      "Add  gd_8                           with p-value 0.0\n",
      "Add  gd_5                           with p-value 1.06662e-259\n",
      "Add  yr_built                       with p-value 2.13466e-172\n",
      "Add  sqft_lot                       with p-value 5.96937e-158\n",
      "Drop yr_renovated                   with p-value 0.227389\n",
      "Add  sqft_living15                  with p-value 1.54428e-156\n",
      "Add  gd_9                           with p-value 1.15128e-98\n",
      "Add  gd_4                           with p-value 4.02446e-52\n",
      "Add  wf_1.0                         with p-value 1.80408e-45\n",
      "Add  con_5                          with p-value 1.15912e-28\n",
      "Add  flr_3.0                        with p-value 3.73789e-26\n",
      "Add  gd_10                          with p-value 2.80616e-24\n",
      "Add  br_2                           with p-value 1.05713e-21\n",
      "Add  bath_3.5                       with p-value 3.4586e-21\n",
      "Add  bath_3.25                      with p-value 9.38687e-14\n",
      "Add  bath_3.75                      with p-value 1.13581e-14\n",
      "Add  con_4                          with p-value 1.90213e-12\n",
      "Add  sqft_lot15                     with p-value 2.30567e-11\n",
      "Add  bath_2.75                      with p-value 4.42309e-08\n",
      "Add  sqft_basement                  with p-value 3.77665e-07\n",
      "Add  sqft_above                     with p-value 6.64523e-36\n",
      "Add  br_3                           with p-value 1.02575e-07\n",
      "Add  yr_renovated                   with p-value 1.00241e-05\n",
      "Drop sqft_living                    with p-value 0.0523466\n",
      "Add  bath_3.0                       with p-value 3.25526e-05\n",
      "Add  bath_1.0                       with p-value 0.000110044\n",
      "Add  con_3                          with p-value 0.000379947\n",
      "Add  bath_1.5                       with p-value 0.000646787\n",
      "Add  bath_4.0                       with p-value 0.000778962\n",
      "Add  bath_2.25                      with p-value 0.00375996\n",
      "Add  bath_4.25                      with p-value 0.00338464\n",
      "resulting features:\n",
      "['gd_6', 'gd_7', 'gd_8', 'gd_5', 'yr_built', 'sqft_lot', 'sqft_living15', 'gd_9', 'gd_4', 'wf_1.0', 'con_5', 'flr_3.0', 'gd_10', 'br_2', 'bath_3.5', 'bath_3.25', 'bath_3.75', 'con_4', 'sqft_lot15', 'bath_2.75', 'sqft_basement', 'sqft_above', 'br_3', 'yr_renovated', 'bath_3.0', 'bath_1.0', 'con_3', 'bath_1.5', 'bath_4.0', 'bath_2.25', 'bath_4.25']\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(X, y, verbose = True)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.611</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1007.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 04 Nov 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:03:52</td>     <th>  Log-Likelihood:    </th> <td>-2.6281e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19842</td>      <th>  AIC:               </th>  <td>5.257e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19810</td>      <th>  BIC:               </th>  <td>5.259e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td> 5.935e+06</td> <td> 9.53e+04</td> <td>   62.290</td> <td> 0.000</td> <td> 5.75e+06</td> <td> 6.12e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_6</th>          <td>-4.828e+05</td> <td> 1.28e+04</td> <td>  -37.604</td> <td> 0.000</td> <td>-5.08e+05</td> <td>-4.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_7</th>          <td>-3.999e+05</td> <td> 1.21e+04</td> <td>  -32.960</td> <td> 0.000</td> <td>-4.24e+05</td> <td>-3.76e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_8</th>          <td>-3.054e+05</td> <td> 1.18e+04</td> <td>  -25.926</td> <td> 0.000</td> <td>-3.29e+05</td> <td>-2.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_5</th>          <td>-5.357e+05</td> <td> 1.56e+04</td> <td>  -34.244</td> <td> 0.000</td> <td>-5.66e+05</td> <td>-5.05e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>      <td>-3048.4661</td> <td>   92.861</td> <td>  -32.828</td> <td> 0.000</td> <td>-3230.482</td> <td>-2866.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot</th>      <td>-1.946e+04</td> <td> 2426.028</td> <td>   -8.022</td> <td> 0.000</td> <td>-2.42e+04</td> <td>-1.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living15</th> <td> 4.423e+04</td> <td> 1594.462</td> <td>   27.740</td> <td> 0.000</td> <td> 4.11e+04</td> <td> 4.74e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_9</th>          <td>-1.753e+05</td> <td> 1.16e+04</td> <td>  -15.158</td> <td> 0.000</td> <td>-1.98e+05</td> <td>-1.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_4</th>          <td>-5.256e+05</td> <td> 3.04e+04</td> <td>  -17.312</td> <td> 0.000</td> <td>-5.85e+05</td> <td>-4.66e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wf_1.0</th>        <td> 2.651e+05</td> <td>  1.9e+04</td> <td>   13.981</td> <td> 0.000</td> <td> 2.28e+05</td> <td> 3.02e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_5</th>         <td> 8.884e+04</td> <td> 1.11e+04</td> <td>    8.003</td> <td> 0.000</td> <td> 6.71e+04</td> <td> 1.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flr_3.0</th>       <td> 6.488e+04</td> <td> 6471.925</td> <td>   10.024</td> <td> 0.000</td> <td> 5.22e+04</td> <td> 7.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gd_10</th>         <td>-8.924e+04</td> <td>  1.2e+04</td> <td>   -7.439</td> <td> 0.000</td> <td>-1.13e+05</td> <td>-6.57e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_2</th>          <td> 3.486e+04</td> <td> 3805.593</td> <td>    9.161</td> <td> 0.000</td> <td> 2.74e+04</td> <td> 4.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.5</th>      <td> 6.274e+04</td> <td> 6478.140</td> <td>    9.684</td> <td> 0.000</td> <td>    5e+04</td> <td> 7.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.25</th>     <td> 5.068e+04</td> <td> 7135.897</td> <td>    7.102</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.75</th>     <td> 1.034e+05</td> <td> 1.49e+04</td> <td>    6.960</td> <td> 0.000</td> <td> 7.43e+04</td> <td> 1.33e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_4</th>         <td> 5.671e+04</td> <td> 1.07e+04</td> <td>    5.308</td> <td> 0.000</td> <td> 3.58e+04</td> <td> 7.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_lot15</th>    <td> -1.66e+04</td> <td> 2370.639</td> <td>   -7.001</td> <td> 0.000</td> <td>-2.12e+04</td> <td>-1.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.75</th>     <td> 2.623e+04</td> <td> 4540.534</td> <td>    5.777</td> <td> 0.000</td> <td> 1.73e+04</td> <td> 3.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_basement</th> <td>   91.3569</td> <td>    3.150</td> <td>   28.999</td> <td> 0.000</td> <td>   85.182</td> <td>   97.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_above</th>    <td>   85.4062</td> <td>    2.791</td> <td>   30.599</td> <td> 0.000</td> <td>   79.935</td> <td>   90.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>br_3</th>          <td> 1.333e+04</td> <td> 2413.551</td> <td>    5.523</td> <td> 0.000</td> <td> 8600.096</td> <td> 1.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th>  <td>  336.0924</td> <td>   96.103</td> <td>    3.497</td> <td> 0.000</td> <td>  147.722</td> <td>  524.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_3.0</th>      <td> 2.629e+04</td> <td> 5706.373</td> <td>    4.607</td> <td> 0.000</td> <td> 1.51e+04</td> <td> 3.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.0</th>      <td>-1.576e+04</td> <td> 3514.795</td> <td>   -4.483</td> <td> 0.000</td> <td>-2.26e+04</td> <td>-8866.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>con_3</th>         <td>  3.83e+04</td> <td> 1.06e+04</td> <td>    3.597</td> <td> 0.000</td> <td> 1.74e+04</td> <td> 5.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_1.5</th>      <td>-1.244e+04</td> <td> 4080.465</td> <td>   -3.048</td> <td> 0.002</td> <td>-2.04e+04</td> <td>-4440.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.0</th>      <td> 5.782e+04</td> <td> 1.63e+04</td> <td>    3.538</td> <td> 0.000</td> <td> 2.58e+04</td> <td> 8.99e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_2.25</th>     <td> 1.019e+04</td> <td> 3455.197</td> <td>    2.948</td> <td> 0.003</td> <td> 3414.511</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bath_4.25</th>     <td> 7.554e+04</td> <td> 2.58e+04</td> <td>    2.931</td> <td> 0.003</td> <td>  2.5e+04</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1211.796</td> <th>  Durbin-Watson:     </th> <td>   1.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2116.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.473</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.290</td>  <th>  Cond. No.          </th> <td>3.24e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.24e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.612\n",
       "Model:                            OLS   Adj. R-squared:                  0.611\n",
       "Method:                 Least Squares   F-statistic:                     1007.\n",
       "Date:                Wed, 04 Nov 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:03:52   Log-Likelihood:            -2.6281e+05\n",
       "No. Observations:               19842   AIC:                         5.257e+05\n",
       "Df Residuals:                   19810   BIC:                         5.259e+05\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const          5.935e+06   9.53e+04     62.290      0.000    5.75e+06    6.12e+06\n",
       "gd_6          -4.828e+05   1.28e+04    -37.604      0.000   -5.08e+05   -4.58e+05\n",
       "gd_7          -3.999e+05   1.21e+04    -32.960      0.000   -4.24e+05   -3.76e+05\n",
       "gd_8          -3.054e+05   1.18e+04    -25.926      0.000   -3.29e+05   -2.82e+05\n",
       "gd_5          -5.357e+05   1.56e+04    -34.244      0.000   -5.66e+05   -5.05e+05\n",
       "yr_built      -3048.4661     92.861    -32.828      0.000   -3230.482   -2866.450\n",
       "sqft_lot      -1.946e+04   2426.028     -8.022      0.000   -2.42e+04   -1.47e+04\n",
       "sqft_living15  4.423e+04   1594.462     27.740      0.000    4.11e+04    4.74e+04\n",
       "gd_9          -1.753e+05   1.16e+04    -15.158      0.000   -1.98e+05   -1.53e+05\n",
       "gd_4          -5.256e+05   3.04e+04    -17.312      0.000   -5.85e+05   -4.66e+05\n",
       "wf_1.0         2.651e+05    1.9e+04     13.981      0.000    2.28e+05    3.02e+05\n",
       "con_5          8.884e+04   1.11e+04      8.003      0.000    6.71e+04    1.11e+05\n",
       "flr_3.0        6.488e+04   6471.925     10.024      0.000    5.22e+04    7.76e+04\n",
       "gd_10         -8.924e+04    1.2e+04     -7.439      0.000   -1.13e+05   -6.57e+04\n",
       "br_2           3.486e+04   3805.593      9.161      0.000    2.74e+04    4.23e+04\n",
       "bath_3.5       6.274e+04   6478.140      9.684      0.000       5e+04    7.54e+04\n",
       "bath_3.25      5.068e+04   7135.897      7.102      0.000    3.67e+04    6.47e+04\n",
       "bath_3.75      1.034e+05   1.49e+04      6.960      0.000    7.43e+04    1.33e+05\n",
       "con_4          5.671e+04   1.07e+04      5.308      0.000    3.58e+04    7.76e+04\n",
       "sqft_lot15     -1.66e+04   2370.639     -7.001      0.000   -2.12e+04   -1.19e+04\n",
       "bath_2.75      2.623e+04   4540.534      5.777      0.000    1.73e+04    3.51e+04\n",
       "sqft_basement    91.3569      3.150     28.999      0.000      85.182      97.532\n",
       "sqft_above       85.4062      2.791     30.599      0.000      79.935      90.877\n",
       "br_3           1.333e+04   2413.551      5.523      0.000    8600.096    1.81e+04\n",
       "yr_renovated    336.0924     96.103      3.497      0.000     147.722     524.463\n",
       "bath_3.0       2.629e+04   5706.373      4.607      0.000    1.51e+04    3.75e+04\n",
       "bath_1.0      -1.576e+04   3514.795     -4.483      0.000   -2.26e+04   -8866.589\n",
       "con_3           3.83e+04   1.06e+04      3.597      0.000    1.74e+04    5.92e+04\n",
       "bath_1.5      -1.244e+04   4080.465     -3.048      0.002   -2.04e+04   -4440.924\n",
       "bath_4.0       5.782e+04   1.63e+04      3.538      0.000    2.58e+04    8.99e+04\n",
       "bath_2.25      1.019e+04   3455.197      2.948      0.003    3414.511     1.7e+04\n",
       "bath_4.25      7.554e+04   2.58e+04      2.931      0.003     2.5e+04    1.26e+05\n",
       "==============================================================================\n",
       "Omnibus:                     1211.796   Durbin-Watson:                   1.965\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2116.189\n",
       "Skew:                           0.473   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.290   Cond. No.                     3.24e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.24e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_fin = X[result]\n",
    "X_with_intercept = sm.add_constant(X_fin)\n",
    "model = sm.OLS(y,X_with_intercept).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 5 most important features\n",
    "linreg = LinearRegression()\n",
    "selector = RFE(linreg, n_features_to_select = 5)\n",
    "selector = selector.fit(X, y.values.ravel()) # convert y to 1d np array to prevent DataConversionWarning\n",
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = X.columns[selector.support_ ]\n",
    "linreg.fit(X[selected_columns],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = linreg.predict(X[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_Residual = np.sum((y-yhat)**2)\n",
    "SS_Total = np.sum((y-np.mean(y))**2)\n",
    "r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X[selected_columns].shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31084956030795596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31067584825923344"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2962662af60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(110)\n",
    "\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = list(range(5,100,5))\n",
    "for t_size in t_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size/100)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(t_sizes, train_err, label='Training Error')\n",
    "plt.scatter(t_sizes, test_err, label='Testing Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
